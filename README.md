# DEEPFAKE-AUDIO

 ğŸ‘‰ğŸ» An audio deepfake is when a â€œclonedâ€ voice that is potentially indistinguishable from the real personâ€™s is used to produce synthetic audio.

 - [Google Colaboratory](https://github.com/Amey-Thakur/DEEPFAKE-AUDIO/blob/main/DEEPFAKE_AUDIO.ipynb)
 
 - [Kaggle](https://www.kaggle.com/ameythakur20/deepfake-audio)
 
 - [Model](https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc)
 
 - [Project Demo](https://youtu.be/i3wnBcbHDbs)

#

This project is an implementation of Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis (SV2TTS) with a vocoder that works in real-time. 

SV2TTS is a three-stage deep learning framework that allows to create a numerical representation of a voice from a few seconds of audio, and to use it to condition a text-to-speech model trained to generate new voices.

---

<p align="center"> <b> ğŸ‘‰ğŸ» Created to Learn the working of Deepfake-Audio ğŸ‘ˆğŸ» <b> </p>
 
<p align="center"> <b> ğŸ‘· Project Authors: Amey Thakur and Mega Satish <b> </p>
 
<p align="center"><a href='https://github.com/Amey-Thakur/COMPUTER-ENGINEERING', style='color: greenyellow;'> âœŒğŸ» Back To Engineering âœŒğŸ»</p>
