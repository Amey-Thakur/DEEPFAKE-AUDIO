# DEEPFAKE-AUDIO

 👉🏻 An audio deepfake is when a “cloned” voice that is potentially indistinguishable from the real person’s is used to produce synthetic audio.

 - [Google Colaboratory](https://github.com/Amey-Thakur/DEEPFAKE-AUDIO/blob/main/DEEPFAKE_AUDIO.ipynb)
 
 - [Kaggle](https://www.kaggle.com/ameythakur20/deepfake-audio)
 
 - [Model](https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc)
 
 - [Project Demo](https://youtu.be/i3wnBcbHDbs)

#

This project is an implementation of Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis (SV2TTS) with a vocoder that works in real-time. 

SV2TTS is a three-stage deep learning framework that allows to create a numerical representation of a voice from a few seconds of audio, and to use it to condition a text-to-speech model trained to generate new voices.

---

<p align="center"> <b> 👉🏻 Created to Learn the working of Deepfake-Audio 👈🏻 <b> </p>
 
<p align="center"> <b> 👷 Project Authors: Amey Thakur and Mega Satish <b> </p>
 
<p align="center"><a href='https://github.com/Amey-Thakur/COMPUTER-ENGINEERING', style='color: greenyellow;'> ✌🏻 Back To Engineering ✌🏻</p>
