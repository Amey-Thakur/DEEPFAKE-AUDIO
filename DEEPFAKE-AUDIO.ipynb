{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/Amey-Thakur/DEEPFAKE-AUDIO/blob/main/DEEPFAKE-AUDIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "X7Om-e0ahXrB"
            },
            "source": [
                "#\n",
                "<h1 align=\"center\">\ud83c\udf99\ufe0f Deepfake Audio</h1>\n",
                "<h3 align=\"center\"><i>A neural voice cloning studio powered by SV2TTS technology</i></h3>\n",
                "\n",
                "<div align=\"center\">\n",
                "\n",
                "| **Author** | **Profiles** |\n",
                "|:---:|:---|\n",
                "| **Amey Thakur** | [![GitHub](https://img.shields.io/badge/GitHub-Amey--Thakur-181717?logo=github)](https://github.com/Amey-Thakur) [![ORCID](https://img.shields.io/badge/ORCID-0000--0001--5644--1575-A6CE39?logo=orcid)](https://orcid.org/0000-0001-5644-1575) [![Google Scholar](https://img.shields.io/badge/Google_Scholar-Amey_Thakur-4285F4?logo=google-scholar&logoColor=white)](https://scholar.google.ca/citations?user=0inooPgAAAAJ&hl=en) [![Kaggle](https://img.shields.io/badge/Kaggle-Amey_Thakur-20BEFF?logo=kaggle)](https://www.kaggle.com/ameythakur20) |\n",
                "| **Mega Satish** | [![GitHub](https://img.shields.io/badge/GitHub-msatmod-181717?logo=github)](https://github.com/msatmod) [![ORCID](https://img.shields.io/badge/ORCID-0000--0002--1844--9557-A6CE39?logo=orcid)](https://orcid.org/0000-0002-1844-9557) [![Google Scholar](https://img.shields.io/badge/Google_Scholar-Mega_Satish-4285F4?logo=google-scholar&logoColor=white)](https://scholar.google.ca/citations?user=7Ajrr6EAAAAJ&hl=en) [![Kaggle](https://img.shields.io/badge/Kaggle-Mega_Satish-20BEFF?logo=kaggle)](https://www.kaggle.com/megasatish) |\n",
                "\n",
                "---\n",
                "\n",
                "**Attribution:** This project builds upon the foundational work of [CorentinJ/Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning).\n",
                "\n",
                "\ud83d\ude80 **Live Demo:** [Hugging Face Space](https://huggingface.co/spaces/ameythakur/Deepfake-Audio) | \ud83c\udfa5 **Video Demo:** [YouTube](https://youtu.be/i3wnBcbHDbs) | \ud83d\udcbb **Repository:** [GitHub](https://github.com/Amey-Thakur/DEEPFAKE-AUDIO)\n",
                "\n",
                "<a href=\"https://youtu.be/i3wnBcbHDbs\">\n",
                "  <img src=\"https://img.youtube.com/vi/i3wnBcbHDbs/0.jpg\" alt=\"Video Demo\" width=\"60%\">\n",
                "</a>\n",
                "\n",
                "</div>\n",
                "\n",
                "## \ud83d\udcd6 Introduction\n",
                "\n",
                "> **An audio deepfake is when a \u201ccloned\u201d voice that is potentially indistinguishable from the real person\u2019s is used to produce synthetic audio.**\n",
                "\n",
                "This research notebook demonstrates the **SV2TTS (Speaker Verification to Text-to-Speech)** framework, a three-stage deep learning pipeline capable of cloning a voice from a mere 5 seconds of audio.\n",
                "\n",
                "### The Pipeline\n",
                "1.  **Speaker Encoder**: Creates a fixed-dimensional embedding (fingerprint) from the reference audio.\n",
                "2.  **Synthesizer**: Generates a Mel Spectrogram from text, conditioned on the speaker embedding.\n",
                "3.  **Vocoder**: Converts the Mel Spectrogram into a raw time-domain waveform (audible speech)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "4kb73A1rhXrE"
            },
            "source": [
                "## \u2601\ufe0f Cloud Environment Setup\n",
                "Execute the following cell **only** if you are running this notebook in a cloud environment like **Google Colab** or **Kaggle**.\n",
                "\n",
                "This script will:\n",
                "1.  **Clone the Repository**: Tries GitHub first, then falls back to **Personal Hugging Face Space** (`ameythakur/Deepfake-Audio`) if GitHub fails.\n",
                "2.  **Environment Detection**: Automatically detects **Kaggle** vs **Colab**.\n",
                "3.  **Data Retrieval**:\n",
                "    *   **Kaggle**: Links directly from `/kaggle/input/deepfakeaudio` (No download needed).\n",
                "    *   **Others**: Attempts Git LFS pull.\n",
                "4.  **Fallback to Kagglehub**: If LFS budget exceeded, downloads from `ameythakur20/deepfakeaudio`.\n",
                "5.  Install all required Python and System dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "bDzcxXrzhXrE",
                "outputId": "060d68bb-0b5c-43a8-f0fd-119d6335404e"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\ud83d\udcbb Detected Google Colab Environment. Initiating setup...\n",
                        "\u2b07\ufe0f Cloning DEEPFAKE-AUDIO repository from MAIN (GitHub)...\n",
                        "Cloning into 'DEEPFAKE-AUDIO'...\n",
                        "remote: Enumerating objects: 682, done.\u001b[K\n",
                        "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
                        "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
                        "remote: Total 682 (delta 7), reused 7 (delta 7), pack-reused 620 (from 1)\u001b[K\n",
                        "Receiving objects: 100% (682/682), 71.95 MiB | 12.37 MiB/s, done.\n",
                        "Resolving deltas: 100% (328/328), done.\n",
                        "Downloading Dataset/encoder.pt (17 MB)\n",
                        "Error downloading object: Dataset/encoder.pt (39373b8): Smudge error: Error downloading Dataset/encoder.pt (39373b86598fa3da9fcddee6142382efe09777e8d37dc9c0561f41f0070f134e): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n",
                        "\n",
                        "Errors logged to /content/DEEPFAKE-AUDIO/.git/lfs/logs/20260129T113138.869344323.log\n",
                        "Use `git lfs logs last` to view the log.\n",
                        "error: external filter 'git-lfs filter-process' failed\n",
                        "fatal: Dataset/encoder.pt: smudge filter lfs failed\n",
                        "warning: Clone succeeded, but checkout failed.\n",
                        "You can inspect what was checked out with 'git status'\n",
                        "and retry with 'git restore --source=HEAD :/'\n",
                        "\n",
                        "\ud83d\udd27 Installing dependencies...\n",
                        "Reading package lists... Done\n",
                        "Building dependency tree... Done\n",
                        "Reading state information... Done\n",
                        "libsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n",
                        "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
                        "\ud83d\udce6 Attempting Git LFS pull...\n",
                        "Updated git hooks.\n",
                        "Git LFS initialized.\n",
                        "Error updating the git index:\n",
                        "error: Source Code/encoder/__init__.py: cannot add to the index - missing --add option?\n",
                        "fatal: Unable to process path Source Code/encoder/__init__.py\n",
                        "\n",
                        "\n",
                        "Errors logged to /content/DEEPFAKE-AUDIO/.git/lfs/logs/20260129T113158.470476122.log\n",
                        "Use `git lfs logs last` to view the log.\n",
                        "batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n",
                        "error: failed to fetch some objects from 'https://github.com/Amey-Thakur/DEEPFAKE-AUDIO.git/info/lfs'\n",
                        "\u26a0\ufe0f GitHub LFS Budget Exceeded or Pull Failed. Using Kaggle Fallback...\n",
                        "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
                        "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
                        "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
                        "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
                        "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n",
                        "\ud83d\ude80 Downloading assets from Kagglehub (ameythakur20/deepfakeaudio)...\n",
                        "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
                        "Downloading from https://www.kaggle.com/api/v1/datasets/download/ameythakur20/deepfakeaudio?dataset_version_number=5...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 550M/550M [00:25<00:00, 22.7MB/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Extracting files...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u2705 Samples linked from Kaggle.\n",
                        "\u2705 Models linked from Kaggle.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import shutil\n",
                "\n",
                "# Detect Cloud Environment (Colab/Kaggle)\n",
                "try:\n",
                "    shell = get_ipython()\n",
                "    if 'google.colab' in str(shell):\n",
                "        print(\"\ud83d\udcbb Detected Google Colab Environment. Initiating setup...\")\n",
                "\n",
                "        # 1. Clone the Repository (GitHub with HF Fallback)\n",
                "        if not os.path.exists(\"DEEPFAKE-AUDIO\"):\n",
                "            print(\"\u2b07\ufe0f Cloning DEEPFAKE-AUDIO repository from MAIN (GitHub)...\")\n",
                "            clone_status = shell.system(\"git clone https://github.com/Amey-Thakur/DEEPFAKE-AUDIO\")\n",
                "\n",
                "            # Fallback to Hugging Face if GitHub clone failed (folder empty or not created)\n",
                "            if not os.path.exists(\"DEEPFAKE-AUDIO\") or not os.listdir(\"DEEPFAKE-AUDIO\"):\n",
                "                print(\"\u26a0\ufe0f GitHub Clone Failed. Attempting Fallback: Personal Hugging Face Space...\")\n",
                "                if os.path.exists(\"DEEPFAKE-AUDIO\"): shutil.rmtree(\"DEEPFAKE-AUDIO\")\n",
                "                shell.system(\"git clone https://huggingface.co/spaces/ameythakur/Deepfake-Audio DEEPFAKE-AUDIO\")\n",
                "                print(\"\u2705 Cloned from Hugging Face Space.\")\n",
                "\n",
                "        os.chdir(\"/content/DEEPFAKE-AUDIO\")\n",
                "\n",
                "        # Install Dependencies (Colab)\n",
                "        print(\"\ud83d\udd27 Installing dependencies...\")\n",
                "        shell.system(\"apt-get install -y libsndfile1\")\n",
                "        shell.system(\"pip install librosa==0.9.2 unidecode webrtcvad inflect umap-learn scikit-learn>=1.3 tqdm scipy 'matplotlib>=3.7,<3.9' Pillow>=10.2 soundfile huggingface_hub\")\n",
                "\n",
                "\n",
                "\n",
                "        # 2. Attempt Git LFS (Colab)\n",
                "        print(\"\ud83d\udce6 Attempting Git LFS pull...\")\n",
                "        shell.system(\"git lfs install\")\n",
                "        lfs_status = shell.system(\"git lfs pull\")\n",
                "\n",
                "        # 3. Check for Fallback (If LFS failed or budget exceeded)\n",
                "        sample_trigger = \"Dataset/samples/Steve Jobs.wav\"\n",
                "        if lfs_status != 0 or not os.path.exists(sample_trigger) or os.path.getsize(sample_trigger) < 1000:\n",
                "            print(\"\u26a0\ufe0f GitHub LFS Budget Exceeded or Pull Failed. Using Kaggle Fallback...\")\n",
                "            shell.system(\"pip install kagglehub\")\n",
                "            import kagglehub\n",
                "            print(\"\ud83d\ude80 Downloading assets from Kagglehub (ameythakur20/deepfakeaudio)...\")\n",
                "            k_path = kagglehub.dataset_download(\"ameythakur20/deepfakeaudio\")\n",
                "\n",
                "            # Link/Copy samples\n",
                "            k_samples = os.path.join(k_path, \"samples\")\n",
                "            if os.path.exists(k_samples):\n",
                "                 if os.path.exists(\"Dataset/samples\"):\n",
                "                      shutil.rmtree(\"Dataset/samples\")\n",
                "                 os.makedirs(\"Dataset\", exist_ok=True)\n",
                "                 os.symlink(k_samples, \"Dataset/samples\")\n",
                "                 print(\"\u2705 Samples linked from Kaggle.\")\n",
                "\n",
                "            # Link/Copy models\n",
                "            for model in [\"encoder.pt\", \"synthesizer.pt\", \"vocoder.pt\"]:\n",
                "                 k_model = os.path.join(k_path, model)\n",
                "                 if os.path.exists(k_model):\n",
                "                      target = os.path.join(\"Dataset\", model)\n",
                "                      if os.path.exists(target): os.remove(target)\n",
                "                      os.symlink(k_model, target)\n",
                "            print(\"\u2705 Models linked from Kaggle.\")\n",
                "\n",
                "    elif \"kaggle\" in os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\"):\n",
                "        print(\"\ud83d\udcbb Detected Kaggle Environment. Initiating setup...\")\n",
                "        os.chdir(\"/kaggle/working\")\n",
                "\n",
                "        # 1. Clone the Repository (GitHub with HF Fallback)\n",
                "        if not os.path.exists(\"DEEPFAKE-AUDIO\"):\n",
                "            print(\"\u2b07\ufe0f Cloning DEEPFAKE-AUDIO repository from MAIN (GitHub)...\")\n",
                "            shell.system(\"git clone https://github.com/Amey-Thakur/DEEPFAKE-AUDIO\")\n",
                "\n",
                "            if not os.path.exists(\"DEEPFAKE-AUDIO\") or not os.listdir(\"DEEPFAKE-AUDIO\"):\n",
                "                print(\"\u26a0\ufe0f GitHub Clone Failed. Attempting Fallback: Personal Hugging Face Space...\")\n",
                "                if os.path.exists(\"DEEPFAKE-AUDIO\"): shutil.rmtree(\"DEEPFAKE-AUDIO\")\n",
                "                shell.system(\"git clone https://huggingface.co/spaces/ameythakur/Deepfake-Audio DEEPFAKE-AUDIO\")\n",
                "                print(\"\u2705 Cloned from Hugging Face Space.\")\n",
                "\n",
                "        os.chdir(\"/kaggle/working/DEEPFAKE-AUDIO\")\n",
                "\n",
                "        # 2. Priority: Link Kaggle Dataset (Skip LFS pull if dataset exists)\n",
                "        kaggle_input = \"/kaggle/input/deepfakeaudio\"\n",
                "        if os.path.exists(kaggle_input):\n",
                "            print(f\"\u2705 Kaggle Dataset Detected at {kaggle_input}. Linking assets...\")\n",
                "            # Link logic specific to Kaggle structure\n",
                "            if os.path.exists(\"Dataset/samples\"):\n",
                "                 shutil.rmtree(\"Dataset/samples\")\n",
                "            if not os.path.exists(\"Dataset\"):\n",
                "                 os.makedirs(\"Dataset\")\n",
                "            # Attempt to symlink folder or copy items\n",
                "            try:\n",
                "                if os.path.exists(os.path.join(kaggle_input, \"samples\")):\n",
                "                    os.symlink(os.path.join(kaggle_input, \"samples\"), \"Dataset/samples\")\n",
                "                for model in [\"encoder.pt\", \"synthesizer.pt\", \"vocoder.pt\"]:\n",
                "                    src = os.path.join(kaggle_input, model)\n",
                "                    dst = os.path.join(\"Dataset\", model)\n",
                "                    if os.path.exists(src):\n",
                "                        if os.path.exists(dst): os.remove(dst)\n",
                "                        os.symlink(src, dst)\n",
                "            except Exception as e: print(f\"Warning during linking: {e}\")\n",
                "            print(\"\u2705 Assets linked from Kaggle Input.\")\n",
                "        else:\n",
                "            print(\"\u26a0\ufe0f Kaggle Input not found. Attempting standard LFS pull...\")\n",
                "            shell.system(\"git lfs install\")\n",
                "            shell.system(\"git lfs pull\")\n",
                "\n",
                "        # Install Dependencies\n",
                "        print(\"\ud83d\udd27 Installing dependencies...\")\n",
                "        shell.system(\"apt-get install -y libsndfile1\")\n",
                "        shell.system(\"pip install librosa==0.9.2 unidecode webrtcvad inflect umap-learn scikit-learn>=1.3 tqdm scipy 'matplotlib>=3.7,<3.9' Pillow>=10.2 soundfile huggingface_hub\")\n",
                "\n",
                "        # 2. Attempt Git LFS\n",
                "        print(\"\ud83d\udce6 Attempting Git LFS pull...\")\n",
                "        shell.system(\"git lfs install\")\n",
                "        lfs_status = shell.system(\"git lfs pull\")\n",
                "\n",
                "        # 3. Check for Fallback (If LFS failed or budget exceeded)\n",
                "        # Detection: If samples folder is empty or contains small pointer files\n",
                "        sample_trigger = \"Dataset/samples/Steve Jobs.wav\"\n",
                "        if lfs_status != 0 or not os.path.exists(sample_trigger) or os.path.getsize(sample_trigger) < 1000:\n",
                "            print(\"\u26a0\ufe0f GitHub LFS Budget Exceeded or Pull Failed. Using Kaggle Fallback...\")\n",
                "            shell.system(\"pip install kagglehub\")\n",
                "            import kagglehub\n",
                "\n",
                "            # Pull from public Kaggle dataset\n",
                "            print(\"\ud83d\ude80 Downloading assets from Kagglehub (ameythakur20/deepfakeaudio)...\")\n",
                "            k_path = kagglehub.dataset_download(\"ameythakur20/deepfakeaudio\")\n",
                "\n",
                "            # Link/Copy samples\n",
                "            k_samples = os.path.join(k_path, \"samples\")\n",
                "            if os.path.exists(k_samples):\n",
                "                 if os.path.exists(\"Dataset/samples\"):\n",
                "                      shutil.rmtree(\"Dataset/samples\")\n",
                "                 os.makedirs(\"Dataset\", exist_ok=True)\n",
                "                 os.symlink(k_samples, \"Dataset/samples\")\n",
                "                 print(\"\u2705 Samples linked from Kaggle.\")\n",
                "\n",
                "            # Link/Copy models\n",
                "            for model in [\"encoder.pt\", \"synthesizer.pt\", \"vocoder.pt\"]:\n",
                "                 k_model = os.path.join(k_path, model)\n",
                "                 if os.path.exists(k_model):\n",
                "                      target = os.path.join(\"Dataset\", model)\n",
                "                      if os.path.exists(target): os.remove(target)\n",
                "                      os.symlink(k_model, target)\n",
                "            print(\"\u2705 Models linked from Kaggle.\")\n",
                "\n",
                "        # 4. Pull Latest Code Changes\n",
                "        print(\"\ud83d\udd04 Synchronizing with remote repository...\")\n",
                "        shell.system(\"git pull\")\n",
                "\n",
                "        # 5. Install System Dependencies\n",
                "        print(\"\ud83d\udd27 Installing system dependencies (libsndfile1)...\")\n",
                "        shell.system(\"apt-get install -y libsndfile1\")\n",
                "\n",
                "        # 6. Install Python Dependencies\n",
                "        print(\"\ud83d\udce6 Installing Python libraries...\")\n",
                "        shell.system(\"pip install librosa==0.9.2 unidecode webrtcvad inflect umap-learn scikit-learn>=1.3 tqdm scipy 'matplotlib>=3.7,<3.9' Pillow>=10.2 soundfile huggingface_hub\")\n",
                "\n",
                "        print(\"\u2705 Environment setup complete. Ready for cloning.\")\n",
                "    else:\n",
                "        print(\"\ud83c\udfe0 Running in local or custom environment. Skipping cloud setup.\")\n",
                "except NameError:\n",
                "    print(\"\ud83c\udfe0 Running in local or custom environment. Skipping cloud setup.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3sJUw_G8hXrG"
            },
            "source": [
                "## 1\ufe0f\u20e3 Model & Data Initialization\n",
                "\n",
                "We prioritize data availability to ensure the notebook runs smoothly regardless of the platform. The system checks for checkpoints in this order:\n",
                "\n",
                "1.  **Repository Local** (`Dataset/` / `Source Code/`): Fast local access if cloned.\n",
                "2.  **Kaggle Dataset** (`/kaggle/input/deepfakeaudio/`): Pre-loaded environment data.\n",
                "    *   *Reference*: [Amey Thakur's Kaggle Dataset](https://www.kaggle.com/datasets/ameythakur20/deepfakeaudio)\n",
                "3.  **Personal Backup** (Hugging Face Space): `ameythakur/Deepfake-Audio`.\n",
                "    *   *Reference*: [Amey Thakur's HF Space](https://huggingface.co/spaces/ameythakur/Deepfake-Audio)\n",
                "4.  **HuggingFace Auto-Download**: Robust fallback for fresh environments.\n",
                "    *   *Reference*: [CorentinJ's SV2TTS Repository](https://huggingface.co/CorentinJ/SV2TTS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "bY79_5WrhXrH",
                "outputId": "c1767603-817a-4f2c-8ce9-a09f2436bc5d"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\ud83d\udcc2 Working Directory: /content/DEEPFAKE-AUDIO\n",
                        "\u2705 Module Path Registered: /content/DEEPFAKE-AUDIO/Source Code\n",
                        "\u2b07\ufe0f Verifying Model Availability...\n",
                        "\u2705 Found high-priority local models in 'Dataset/'. Verified.\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import zipfile\n",
                "import shutil\n",
                "\n",
                "# Determine if running in Google Colab\n",
                "IS_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "# Register 'Source Code' to Python path for module imports\n",
                "source_path = os.path.abspath(\"Source Code\")\n",
                "if source_path not in sys.path:\n",
                "    sys.path.append(source_path)\n",
                "\n",
                "print(f\"\ud83d\udcc2 Working Directory: {os.getcwd()}\")\n",
                "print(f\"\u2705 Module Path Registered: {source_path}\")\n",
                "\n",
                "# Define paths for model checkpoints\n",
                "extract_path = \"pretrained_models\"\n",
                "\n",
                "if not os.path.exists(extract_path):\n",
                "    os.makedirs(extract_path)\n",
                "\n",
                "# --- \ud83e\udde0 Checkpoint Verification Strategy ---\n",
                "print(\"\u2b07\ufe0f Verifying Model Availability...\")\n",
                "\n",
                "# Priority 1: Check Local Repository 'Dataset/' folder\n",
                "core_models = [\"encoder.pt\", \"synthesizer.pt\", \"vocoder.pt\"]\n",
                "\n",
                "def is_valid_pt(p):\n",
                "    \"\"\"Checks if a file exists and is not an LFS pointer (typically < 1KB).\"\"\"\n",
                "    return os.path.exists(p) and os.path.getsize(p) > 1000\n",
                "\n",
                "dataset_models_present = all([is_valid_pt(os.path.join(\"Dataset\", m)) for m in core_models])\n",
                "\n",
                "if dataset_models_present:\n",
                "    print(\"\u2705 Found high-priority local models in 'Dataset/'. Verified.\")\n",
                "else:\n",
                "    # Priority 2: Check Kaggle Dataset (Online Pre-loaded environment data)\n",
                "    kaggle_path = \"/kaggle/input/deepfakeaudio\"\n",
                "    kaggle_models_present = all([is_valid_pt(os.path.join(kaggle_path, m)) for m in core_models])\n",
                "\n",
                "    if kaggle_models_present:\n",
                "        print(f\"\u2705 Found hardcoded Kaggle Dataset models at {kaggle_path}. Skipping download.\")\n",
                "    else:\n",
                "        print(\"\u26a0\ufe0f Models not found or are LFS pointers. Attempting fallback download...\")\n",
                "\n",
                "        # Priority 3: Personal Hugging Face Space (ameythakur/Deepfake-Audio)\n",
                "        personal_hf_success = False\n",
                "        try:\n",
                "            print(\"\ud83d\ude80 Attempting download from Personal Hugging Face Space (ameythakur/Deepfake-Audio)...\")\n",
                "            from huggingface_hub import hf_hub_download\n",
                "            os.makedirs(\"pretrained_models\", exist_ok=True)\n",
                "            for model in core_models:\n",
                "                 try:\n",
                "                     fpath = hf_hub_download(repo_id=\"ameythakur/Deepfake-Audio\", filename=f\"Dataset/{model}\", repo_type=\"space\", local_dir=\"pretrained_models\")\n",
                "                 except:\n",
                "                     fpath = hf_hub_download(repo_id=\"ameythakur/Deepfake-Audio\", filename=model, repo_type=\"space\", local_dir=\"pretrained_models\")\n",
                "                 target = os.path.join(\"pretrained_models\", model)\n",
                "                 if fpath != target and os.path.exists(fpath): shutil.move(fpath, target)\n",
                "            if os.path.exists(os.path.join(\"pretrained_models\", \"Dataset\")): shutil.rmtree(os.path.join(\"pretrained_models\", \"Dataset\"))\n",
                "            print(\"\u2705 Models successfully acquired via Personal Hugging Face fallback.\")\n",
                "            personal_hf_success = True\n",
                "        except Exception as e_hf:\n",
                "            print(f\"\u26a0\ufe0f Personal HF Checkpoint failed: {e_hf}. Trying External Fallback...\")\n",
                "\n",
                "        # Priority 4 (Fallback): Auto-download from HuggingFace via utils script\n",
                "        if not personal_hf_success:\n",
                "            try:\n",
                "                from utils.default_models import ensure_default_models\n",
                "                ensure_default_models(Path(\"pretrained_models\"))\n",
                "                print(\"\u2705 Models successfully acquired via External HuggingFace fallback.\")\n",
                "            except Exception as e:\n",
                "                print(f\"\u26a0\ufe0f Critical: Could not auto-download models. Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ycvMxmYJhXrI"
            },
            "source": [
                "## 2\ufe0f\u20e3 Architecture Loading\n",
                "\n",
                "We now initialize the three distinct neural networks that comprise the SV2TTS framework. Please ensure you are running on a **GPU Runtime** (e.g., T4 on Colab) for optimal performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "yEShAzbfhXrI",
                "outputId": "9d2ce872-19a3-4259-a10b-8afebb394b28"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\ud83c\udfaf Computation Device: cuda\n",
                        "\u23f3 Loading Neural Networks (SV2TTS Pipeline)...\n",
                        "\ud83d\udfe2 Loading Encoder from Repository: Dataset/encoder.pt\n",
                        "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
                        "\ud83d\udfe2 Loading Synthesizer from Repository: Dataset/synthesizer.pt\n",
                        "Synthesizer using device: cuda\n",
                        "\ud83d\udfe2 Loading Vocoder from Repository: Dataset/vocoder.pt\n",
                        "Building Wave-RNN\n",
                        "Trainable Parameters: 4.481M\n",
                        "Loading model weights at Dataset/vocoder.pt\n",
                        "\u2705 Pipeline operational. All components loaded correctly.\n"
                    ]
                }
            ],
            "source": [
                "from encoder import inference as encoder\n",
                "from synthesizer.inference import Synthesizer\n",
                "from vocoder import inference as vocoder\n",
                "import numpy as np\n",
                "import torch\n",
                "from pathlib import Path\n",
                "\n",
                "# Hardware Acceleration Check\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"\ud83c\udfaf Computation Device: {device}\")\n",
                "\n",
                "def resolve_checkpoint(component_name, legacy_path_suffix):\n",
                "    \"\"\"\n",
                "    Intelligently resolves the path to model checkpoints based on priority.\n",
                "    1. Repository /Dataset/ folder.\n",
                "    2. Kaggle Input directory (Hardcoded: /kaggle/input/deepfakeaudio/).\n",
                "    3. Auto-downloaded 'pretrained_models'.\n",
                "    \"\"\"\n",
                "\n",
                "    def is_valid(p):\n",
                "        return p.exists() and p.stat().st_size > 1000\n",
                "\n",
                "    # 1. Repository Local (Dataset/)\n",
                "    dataset_p = Path(\"Dataset\") / f\"{component_name.lower()}.pt\"\n",
                "    if is_valid(dataset_p):\n",
                "        print(f\"\ud83d\udfe2 Loading {component_name} from Repository: {dataset_p}\")\n",
                "        return dataset_p\n",
                "\n",
                "    # 2. Kaggle Environment (Hardcoded Path: /kaggle/input/deepfakeaudio/)\n",
                "    kaggle_p = Path(\"/kaggle/input/deepfakeaudio\") / f\"{component_name.lower()}.pt\"\n",
                "    if is_valid(kaggle_p):\n",
                "        print(f\"\ud83d\udfe2 Loading {component_name} from Kaggle: {kaggle_p}\")\n",
                "        return kaggle_p\n",
                "\n",
                "    # 3. Default / Auto-Downloaded Fallback\n",
                "    default_p = Path(\"pretrained_models/default\") / f\"{component_name.lower()}.pt\"\n",
                "    if is_valid(default_p):\n",
                "        print(f\"\ud83d\udfe2 Loading {component_name} from Fallback: {default_p}\")\n",
                "        return default_p\n",
                "\n",
                "    # 4. Legacy/Manual Paths\n",
                "    legacy_p = Path(\"pretrained_models\") / legacy_path_suffix\n",
                "    if legacy_p.exists():\n",
                "         if legacy_p.is_dir():\n",
                "             pts = [f for f in legacy_p.glob(\"*.pt\") if is_valid(f)]\n",
                "             if pts: return pts[0]\n",
                "             pts_rec = [f for f in legacy_p.rglob(\"*.pt\") if is_valid(f)]\n",
                "             if pts_rec: return pts_rec[0]\n",
                "         elif is_valid(legacy_p):\n",
                "             return legacy_p\n",
                "\n",
                "    print(f'\u26a0\ufe0f Warning: {component_name} checkpoint not found! Falling back to dynamic search...')\n",
                "    return None\n",
                "\n",
                "print(\"\u23f3 Loading Neural Networks (SV2TTS Pipeline)...\")\n",
                "\n",
                "try:\n",
                "    # 1. Encoder: Extract speaker embedding\n",
                "    encoder_path = resolve_checkpoint(\"Encoder\", \"encoder/saved_models\")\n",
                "    encoder.load_model(encoder_path)\n",
                "\n",
                "    # 2. Synthesizer: Generates spectrograms from text\n",
                "    synth_path = resolve_checkpoint(\"Synthesizer\", \"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n",
                "    synthesizer = Synthesizer(synth_path)\n",
                "\n",
                "    # 3. Vocoder: Converts spectrograms to audio waveforms\n",
                "    vocoder_path = resolve_checkpoint(\"Vocoder\", \"vocoder/saved_models/pretrained\")\n",
                "    vocoder.load_model(vocoder_path)\n",
                "\n",
                "    print(\"\u2705 Pipeline operational. All components loaded correctly.\")\n",
                "except Exception as e:\n",
                "    print(f\"\u274c Architecture Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "GjaGAUyVhXrJ"
            },
            "source": [
                "## 3\ufe0f\u20e3 Inference Interface\n",
                "\n",
                "Select your **Input Method** below to begin cloning.\n",
                "\n",
                "*   **Presets**: Choose from a high-quality list of celebrity samples.\n",
                "*   **Upload**: Use your own `.wav` or `.mp3` file (5-10 seconds recommended).\n",
                "*   **Record**: Capture your voice directly in the browser (Colab only)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000,
                    "referenced_widgets": [
                        "17941275da2c4712a8f7aeee24e985dc",
                        "d35d66d0fc6f4956a22315288f75761e",
                        "e5738978acde489493cc00b7580b41bf",
                        "a1c213e8e9ed4e6a80611f91e37c16ee",
                        "2a6b69d651c24930b892c0bb52e9d9e4",
                        "39339f0b568c4d5084de7664d336ba50",
                        "0923c7a8ae574c4fa2c9eb8c25076b95",
                        "b0a46e803d84423cacb55e37ae6c043b",
                        "bb70b9f36452494da95ee1033601218f",
                        "f3008160ab52453d932a0cb62c711eee",
                        "f035a503fafe48038036bdd50bd07b1c",
                        "dac9a6ef6db347e08b2268c5e5654008",
                        "779855519a5844d3bcc1ed69a8c44608",
                        "05f5b43427fe47fbae468c4cec2be72c",
                        "98051b53e539482aadf5d4b132dd3021",
                        "3ed45fa49669481dbee831dfb2f6ebeb",
                        "9d9b4954b5a74bf2b2f0fef974564bda",
                        "3753f04d0dbb48a6a9a5c5589425ad91",
                        "c294dc1d01e3421097eefe7eb2e5e377",
                        "de81a54ce89a4aaeaba52f01c571b212",
                        "7dbdc18b94a54cb6a492c7f33a661a56",
                        "b9b8b1f96c3d4b89a9bc3e32d6076ad3",
                        "91e19a809309432995d435aeba1e8bde",
                        "c51b8d7f054b41039f354fce639d6947",
                        "20d72122af6f449c90d53871c5a29b7d",
                        "f73ef86eeaab452eb11e45f1e17464a8",
                        "edf2d4f03fae4c5da75d0e3e1ad60382"
                    ]
                },
                "id": "3wq8NsHohXrJ",
                "outputId": "b92ea5cd-958b-4f83-9c48-1726f5f821a1"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Select Input Method:\n",
                        "\u2705 Samples located at: /content/DEEPFAKE-AUDIO/Dataset/samples\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Tab(children=(VBox(children=(Dropdown(description='Preset:', options=('Donald Trump.wav', 'Steve Jobs.wav', 'A\u2026"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "17941275da2c4712a8f7aeee24e985dc"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Textarea(value=\"Hello, I'm Elon Musk. Welcome to Deepfake Audio by Amey Thakur and Mega Satish. Explore AI voi\u2026"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "de81a54ce89a4aaeaba52f01c571b212"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Button(button_style='primary', description='Clone Voice! \ud83d\ude80', style=ButtonStyle())"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "91e19a809309432995d435aeba1e8bde"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Output()"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "f73ef86eeaab452eb11e45f1e17464a8"
                        }
                    },
                    "metadata": {}
                }
            ],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display, Javascript, Audio\n",
                "try:\n",
                "    from google.colab import output\n",
                "    HAS_COLAB = True\n",
                "except ImportError:\n",
                "    HAS_COLAB = False\n",
                "from base64 import b64decode\n",
                "import io\n",
                "import librosa\n",
                "import librosa.display\n",
                "import os\n",
                "import soundfile as sf\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import glob\n",
                "\n",
                "RECORD = \"\"\"\n",
                "const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
                "const b2text = blob => new Promise(resolve => {\n",
                "  const reader = new FileReader()\n",
                "  reader.onloadend = e => resolve(e.srcElement.result)\n",
                "  reader.readAsDataURL(blob)\n",
                "})\n",
                "var record = time => new Promise(async resolve => {\n",
                "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
                "  recorder = new MediaRecorder(stream)\n",
                "  chunks = []\n",
                "  recorder.ondataavailable = e => chunks.push(e.data)\n",
                "  recorder.start()\n",
                "  await sleep(time)\n",
                "  recorder.onstop = async ()=>{\n",
                "    blob = new Blob(chunks)\n",
                "    text = await b2text(blob)\n",
                "    resolve(text)\n",
                "  }\n",
                "  recorder.stop()\n",
                "})\"\"\"\n",
                "\n",
                "def record_audio(sec=10):\n",
                "    if not HAS_COLAB:\n",
                "        raise RuntimeError(\"Recording is only available in a Google Colab environment.\")\n",
                "    print(\"\ud83d\udd34 Recording active for %d seconds...\" % sec)\n",
                "    display(Javascript(RECORD))\n",
                "    s = output.eval_js('record(%d)' % (sec*1000))\n",
                "    print(\"\u2705 Recording saved.\")\n",
                "    binary = b64decode(s.split(',')[1])\n",
                "    with open('recording.wav', 'wb') as f:\n",
                "        f.write(binary)\n",
                "    return 'recording.wav'\n",
                "\n",
                "def visualize_results(original_wav, generated_wav, spec, embed, title=\"Analysis\"):\n",
                "    try:\n",
                "        fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
                "        axes[0].set_title(\"Input Voice vs. Cloned Voice (Waveform)\")\n",
                "        try:\n",
                "            librosa.display.waveshow(original_wav, alpha=0.5, ax=axes[0], label=\"Original\")\n",
                "            librosa.display.waveshow(generated_wav, alpha=0.5, ax=axes[0], label=\"Cloned\", color='r')\n",
                "            axes[0].legend()\n",
                "        except:\n",
                "            axes[0].plot(original_wav, alpha=0.5, label=\"Original\")\n",
                "            axes[0].plot(generated_wav, alpha=0.5, label=\"Cloned\", color='r')\n",
                "            axes[0].legend()\n",
                "\n",
                "        axes[1].set_title(\"Generated Mel Spectrogram\")\n",
                "        im = axes[1].imshow(spec, aspect=\"auto\", origin=\"lower\", interpolation='none')\n",
                "        fig.colorbar(im, ax=axes[1])\n",
                "\n",
                "        axes[2].set_title(\"Speaker Embedding (256-D Heatmap)\")\n",
                "        if len(embed) == 256:\n",
                "            axes[2].imshow(embed.reshape(16, 16), aspect='auto', cmap='viridis')\n",
                "        else:\n",
                "            axes[2].plot(embed)\n",
                "\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    except Exception as e:\n",
                "        print(f\"\u26a0\ufe0f Graphs partially failed: {e}. Audio was successful.\")\n",
                "\n",
                "# --- \ud83d\udee1\ufe0f IMPROVED SAMPLE DISCOVERY ---\n",
                "def find_samples_dir():\n",
                "    \"\"\"Locates reference samples with high persistence across all environments.\"\"\"\n",
                "    # Priority paths\n",
                "    priority_roots = [\n",
                "        \"Source Code/samples\",\n",
                "        \"Dataset/samples\",\n",
                "        \"D:/GitHub/DEEPFAKE-AUDIO/Source Code/samples\",\n",
                "        \"D:/GitHub/DEEPFAKE-AUDIO/Dataset/samples\",\n",
                "        \"/content/DEEPFAKE-AUDIO/Source Code/samples\",\n",
                "        \"/kaggle/input/deepfakeaudio/samples\",\n",
                "        \"/kaggle/input/deepfakeaudio\"\n",
                "    ]\n",
                "\n",
                "    def filter_real_audio(d):\n",
                "        if not os.path.exists(d): return []\n",
                "        # Check if files are real audio (not small LFS pointers < 1KB)\n",
                "        return [f for f in os.listdir(d) if f.lower().endswith((\".wav\", \".mp3\")) and os.path.getsize(os.path.join(d, f)) > 1024]\n",
                "\n",
                "    for d in priority_roots:\n",
                "        files = filter_real_audio(d)\n",
                "        if files:\n",
                "            print(f\"\u2705 Samples located at: {os.path.abspath(d)}\")\n",
                "            return d, files\n",
                "\n",
                "    # More aggressive glob search\n",
                "    print(\"\ud83d\udd0d Searching folders for audio samples...\")\n",
                "    potential_matches = glob.glob(\"**/samples/*.wav\", recursive=True) + glob.glob(\"**/samples/*.mp3\", recursive=True)\n",
                "    valid_matches = [m for m in potential_matches if os.path.getsize(m) > 1024]\n",
                "\n",
                "    if valid_matches:\n",
                "        root = os.path.dirname(valid_matches[0])\n",
                "        files = [os.path.basename(f) for f in glob.glob(os.path.join(root, \"*.*\")) if f.lower().endswith((\".wav\", \".mp3\")) and os.path.getsize(f) > 1024]\n",
                "        print(f\"\u2728 Located samples via glob at: {os.path.abspath(root)}\")\n",
                "        return root, files\n",
                "\n",
                "    return None, []\n",
                "\n",
                "print(\"Select Input Method:\")\n",
                "tab = widgets.Tab()\n",
                "\n",
                "samples_dir, preset_files = find_samples_dir()\n",
                "if samples_dir:\n",
                "    preset_files.sort()\n",
                "    for name in reversed([\"Donald Trump.wav\", \"Steve Jobs.wav\"]):\n",
                "        if name in preset_files:\n",
                "            preset_files.insert(0, preset_files.pop(preset_files.index(name)))\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f Warning: No reference samples found. Please run the setup cell or upload manually.\")\n",
                "\n",
                "dropdown = widgets.Dropdown(options=preset_files,\n",
                "                            value=preset_files[0] if preset_files else None,\n",
                "                            description='Preset:')\n",
                "uploader = widgets.FileUpload(accept='.wav,.mp3', multiple=False)\n",
                "record_btn = widgets.Button(description=\"Start Recording (10s)\", button_style='danger')\n",
                "record_out = widgets.Output()\n",
                "\n",
                "def on_record_click(b):\n",
                "    with record_out:\n",
                "        record_btn.disabled = True\n",
                "        try: record_audio(10)\n",
                "        except Exception as e: print(f\"Error: {e}.\")\n",
                "        record_btn.disabled = False\n",
                "record_btn.on_click(on_record_click)\n",
                "\n",
                "# Tab assignment MUST use .children attribute\n",
                "tab.children = [\n",
                "    widgets.VBox([dropdown]),\n",
                "    widgets.VBox([uploader]),\n",
                "    widgets.VBox([record_btn, record_out])\n",
                "]\n",
                "tab.set_title(0, '\ud83c\udfb5 Presets')\n",
                "tab.set_title(1, '\ud83d\udcc2 Upload')\n",
                "tab.set_title(2, '\ud83d\udd34 Record')\n",
                "display(tab)\n",
                "\n",
                "text_input = widgets.Textarea(\n",
                "    value=\"Hello, I'm Elon Musk. Welcome to Deepfake Audio by Amey Thakur and Mega Satish. Explore AI voice Go!\",\n",
                "    placeholder='Enter text to synthesize...',\n",
                "    description='Text:',\n",
                "    layout=widgets.Layout(width='50%', height='100px')\n",
                ")\n",
                "clone_btn = widgets.Button(description=\"Clone Voice! \ud83d\ude80\", button_style='primary')\n",
                "out = widgets.Output()\n",
                "display(text_input, clone_btn, out)\n",
                "\n",
                "def run_cloning(b):\n",
                "    with out:\n",
                "        out.clear_output()\n",
                "        active_tab = tab.selected_index\n",
                "        input_path = None\n",
                "        try:\n",
                "            if active_tab == 0:\n",
                "                 if not dropdown.value: return print(\"\u274c No preset selected.\")\n",
                "                 input_path = os.path.join(samples_dir, dropdown.value)\n",
                "                 print(f\"\ud83c\udf99\ufe0f Source: Preset ({dropdown.value})\")\n",
                "            elif active_tab == 1:\n",
                "                 if not uploader.value: return print(\"\u274c No file uploaded.\")\n",
                "                 fname = list(uploader.value.keys())[0]\n",
                "                 content = uploader.value[fname]['content']\n",
                "                 input_path = \"uploaded_sample.wav\"\n",
                "                 with open(input_path, \"wb\") as f: f.write(content)\n",
                "                 print(f\"\ud83c\udf99\ufe0f Source: Upload ({fname})\")\n",
                "            elif active_tab == 2:\n",
                "                 if not os.path.exists(\"recording.wav\"): return print(\"\u274c No recording found.\")\n",
                "                 input_path = \"recording.wav\"\n",
                "                 print(\"\ud83c\udf99\ufe0f Source: Microphone\")\n",
                "\n",
                "            print(\"\u23f3 Step 1/3: Encoding speaker identity...\")\n",
                "            original_wav, sampling_rate = librosa.load(input_path)\n",
                "            preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
                "            embed = encoder.embed_utterance(preprocessed_wav)\n",
                "            print(\"\u23f3 Step 2/3: Synthesizing speech...\")\n",
                "            specs = synthesizer.synthesize_spectrograms([text_input.value], [embed])\n",
                "            spec = specs[0]\n",
                "            print(\"\u23f3 Step 3/3: Generating waveform...\")\n",
                "            generated_wav = vocoder.infer_waveform(spec)\n",
                "            print(\"\ud83c\udf89 Synthesis Complete!\")\n",
                "            display(Audio(generated_wav, rate=synthesizer.sample_rate))\n",
                "            print(\"\\n\ud83d\udcca Generating Analysis...\")\n",
                "            visualize_results(original_wav, generated_wav, spec, embed)\n",
                "        except Exception as e: print(f\"\u274c Error: {e}\")\n",
                "clone_btn.on_click(run_cloning)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "colab": {
            "provenance": [],
            "gpuType": "T4",
            "include_colab_link": true
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 0
}